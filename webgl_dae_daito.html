<!DOCTYPE html>
<html lang="en">
<head>
	<title>three.ar.js - Load Model</title>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, user-scalable=no,
	minimum-scale=1.0, maximum-scale=1.0">
	<style>
		body {
			font-family: monospace;
			margin: 0;
			overflow: hidden;
			position: fixed;
			width: 100%;
			height: 100vh;
			-webkit-user-select: none;
			user-select: none;
		}
		canvas {
			position: absolute;
			top: 0;
			left: 0;
		}
		#info {
			position: absolute;
			left: calc(50% - 75px);
			bottom: 10px;
			z-index: 10;
			display: block;
			text-align: center;
			background-color: rgba(0, 0, 	0, 0.4);
			padding: 4px 8px;
		}
		#info a {
			color: white;
			text-decoration: none;
		}
	</style>
</head>
<body>
<div id="info">
	<a href="index.html">webar experiments</a>
</div>
<script src="js/three.js"></script>
<script src="js/three.ar.js"></script>
<script src="js/VRControls.js"></script>
<script src="js/ColladaLoader.js"></script>
<script src="js/inflate.min.js"></script>
<script>

var vrDisplay;
var vrControls;
var arView;

var canvas;
var camera;
var scene;
var renderer;
var model;

var shadowMesh;
var planeGeometry;
var light;
var directionalLight;

var clock = new THREE.Clock();

var mixers = [];

/**
 * Use the `getARDisplay()` utility to leverage the WebVR API
 * to see if there are any AR-capable WebVR VRDisplays. Returns
 * a valid display if found. Otherwise, display the unsupported
 * browser message.
 */
THREE.ARUtils.getARDisplay().then(function (display) {
	if (display) {
		vrDisplay = display;
		init();
	} else {
		THREE.ARUtils.displayUnsupportedMessage();
	}
});

function init() {

	scene = new THREE.Scene();

	// Turn on the debugging panel
	var arDebug = new THREE.ARDebug(vrDisplay, scene, {
		showLastHit: false,
		showPoseStatus: false,
		showPlanes: true
	} );
	document.body.appendChild(arDebug.getElement());

	// Setup the three.js rendering environment
	renderer = new THREE.WebGLRenderer({ alpha: true });
	renderer.setPixelRatio(window.devicePixelRatio);
	renderer.setSize(window.innerWidth, window.innerHeight);
	renderer.autoClear = false;
	canvas = renderer.domElement;
	document.body.appendChild(canvas);

	// Creating the ARView, which is the object that handles
	// the rendering of the camera stream behind the three.js
	// scene
	arView = new THREE.ARView(vrDisplay, renderer);

	// The ARPerspectiveCamera is very similar to THREE.PerspectiveCamera,
	// except when using an AR-capable browser, the camera uses
	// the projection matrix provided from the device, so that the
	// perspective camera's depth planes and field of view matches
	// the physical camera on the device.
	camera = new THREE.ARPerspectiveCamera(
		vrDisplay,
		60,
		window.innerWidth / window.innerHeight,
		vrDisplay.depthNear,
		vrDisplay.depthFar
	);

	// VRControls is a utility from three.js that applies the device's
	// orientation/position to the perspective camera, keeping our
	// real world and virtual world in sync.
	vrControls = new THREE.VRControls(camera);

	// For shadows to work
	renderer.shadowMap.enabled = true;
	renderer.shadowMap.type = THREE.PCFSoftShadowMap;

	// The materials in Poly models will render as a black mesh
	// without lights in our scenes. Let's add an ambient light
	// so our model can be scene, as well as a directional light
	// for the shadow
	directionalLight = new THREE.DirectionalLight();
	// @TODO in the future, use AR light estimation
	directionalLight.intensity = 0.5;
	directionalLight.position.set(-1, 15, 1);
	// We want this light to cast shadow
	directionalLight.castShadow = true;
	directionalLight.shadow.camera.zoom = 5.0;
	light = new THREE.AmbientLight();
	scene.add(light);
	scene.add(directionalLight);

	// Make a large plane to receive our shadows
	planeGeometry = new THREE.PlaneGeometry(2000, 2000);
	// Rotate our plane to be parallel to the floor
	planeGeometry.rotateX(-Math.PI / 2);

	// Create a mesh with a shadow material, resulting in a mesh
	// that only renders shadows once we flip the `receiveShadow` property
	shadowMesh = new THREE.Mesh(planeGeometry, new THREE.ShadowMaterial({
		color: 0x111111,
		opacity: 0.15,
	}));
	shadowMesh.receiveShadow = true;
	scene.add(shadowMesh);

	var loader = new THREE.ColladaLoader();
	loader.load( 'models/daito/_daito_t_low_idle_2.dae', function (collada) {

		model = collada.scene;

		model.traverse( function (mesh) {

			if ( mesh.isMesh ) {

				mesh.castShadow = true;
				mesh.receiveShadow = true;

				// workarounds

				mesh.material.opacity = 1;
				mesh.material.transparent = false;
				mesh.frustumCulled = false;

			}

		} );
		model.position.set(10000, 10000, 10000);
		model.scale.setScalar(0.001);
		scene.add(model);

		//

		var animations = collada.animations;

		var mixer = new THREE.AnimationMixer(model);
		mixer.clipAction(animations[0]).play();
		mixers.push(mixer);

	} );

	// Bind our event handlers
	window.addEventListener('resize', onWindowResize, false);
	canvas.addEventListener('click', onClick, false);

	// Kick off the render loop!
	update();
}

/**
 * The render loop, called once per frame. Handles updating
 * our scene and rendering.
 */
function update() {
	// Clears color from the frame before rendering the camera (arView) or scene.
	renderer.clearColor();

	// Render the device's camera stream on screen first of all.
	// It allows to get the right pose synchronized with the right frame.
	arView.render();

	// Update our camera projection matrix in the event that
	// the near or far planes have updated
	camera.updateProjectionMatrix();

	// Update our perspective camera's positioning
	vrControls.update();

	if ( mixers.length > 0 ) {

		for ( var i = 0; i < mixers.length; i ++ ) {

			mixers[ i ].update( clock.getDelta() );

		}

	}

	// Render our three.js virtual scene
	renderer.clearDepth();
	renderer.render(scene, camera);

	// Kick off the requestAnimationFrame to call this function
	// when a new VRDisplay frame is rendered
	vrDisplay.requestAnimationFrame(update);
}

/**
 * On window resize, update the perspective camera's aspect ratio,
 * and call `updateProjectionMatrix` so that we can get the latest
 * projection matrix provided from the device
 */
function onWindowResize () {
	camera.aspect = window.innerWidth / window.innerHeight;
	camera.updateProjectionMatrix();
	renderer.setSize(window.innerWidth, window.innerHeight);
}

/**
 * When clicking on the screen, fire a ray from where the user clicked
 * on the screen and if a hit is found, place a cube there.
 */
function onClick (e) {
	// Inspect the event object and generate normalize screen coordinates
	// (between 0 and 1) for the screen position.
	var x = e.clientX / window.innerWidth;
	var y = e.clientY / window.innerHeight;

	// Send a ray from the point of click to the real world surface
	// and attempt to find a hit. `hitTest` returns an array of potential
	// hits.
	var hits = vrDisplay.hitTest(x, y);

	if (!model) {
		console.warn('Model not yet loaded');
		return;
	}

	// If a hit is found, just use the first one
	if (hits && hits.length) {
		var hit = hits[0];

		// Turn the model matrix from the VRHit into a
		// THREE.Matrix4 so we can extract the position
		// elements out so we can position the shadow mesh
		// to be directly under our model. This is a complicated
		// way to go about it to illustrate the process, and could
		// be done by manually extracting the "Y" value from the
		// hit matrix via `hit.modelMatrix[13]`
		var matrix = new THREE.Matrix4();
		var position = new THREE.Vector3();
		matrix.fromArray(hit.modelMatrix);
		position.setFromMatrixPosition(matrix);

		// Set our shadow mesh to be at the same Y value
		// as our hit where we're placing our model
		// @TODO use the rotation from hit.modelMatrix
		shadowMesh.position.y = position.y;

		// Use the `placeObjectAtHit` utility to position
		// the cube where the hit occurred
		THREE.ARUtils.placeObjectAtHit(model,  // The object to place
																	 hit,   // The VRHit object to move the cube to
																	 1,     // Easing value from 0 to 1; we want to move
																					// the cube directly to the hit position
																	 true); // Whether or not we also apply orientation

		// Rotate the model to be facing the user
		var angle = Math.atan2(
			camera.position.x - model.position.x,
			camera.position.z - model.position.z
		);
		model.rotation.set(0, angle, 0);
	}
}
</script>
</body>
</html>
